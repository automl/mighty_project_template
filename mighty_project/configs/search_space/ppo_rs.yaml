# configs/search_space/ppo_rs.yaml
hyperparameters:
  # match the keys under algorithm_kwargs in your PPO config
  algorithm_kwargs.learning_rate:
    type: uniform_float
    lower: 1e-5
    upper: 1e-3
    log: true
  algorithm_kwargs.batch_size:
    type: categorical
    choices: [8192, 16384, 32768]
  algorithm_kwargs.n_gradient_steps:
    type: uniform_int
    lower: 1
    upper: 20
    log: false
  algorithm_kwargs.gamma:
    type: uniform_float
    lower: 0.9
    upper: 0.9999
    log: false
  algorithm_kwargs.ppo_clip:
    type: uniform_float
    lower: 0.1
    upper: 0.3
    log: false
  algorithm_kwargs.value_loss_coef:
    type: uniform_float
    lower: 0.1
    upper: 1.0
    log: false
  algorithm_kwargs.entropy_coef:
    type: uniform_float
    lower: 0.0
    upper: 0.1
    log: false
  algorithm_kwargs.max_grad_norm:
    type: uniform_float
    lower: 0.1
    upper: 1.0
    log: false
